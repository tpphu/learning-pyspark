{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "911c980a-3948-422b-b62d-c36b74ca940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "# Define data\n",
    "data = [\n",
    "    ('James', '', 'Smith', '1991-04-01', 'M', 3000),\n",
    "    ('Michael', 'Rose', '', '2000-05-19', 'M', 4000),\n",
    "    ('Robert', '', 'Williams', '1978-09-05', 'M', 4000),\n",
    "    ('Maria', 'Anne', 'Jones', '1967-12-01', 'F', 4000),\n",
    "    ('Jen', 'Mary', 'Brown', '1980-02-17', 'F', -1)\n",
    "]\n",
    "\n",
    "# Define columns\n",
    "columns = [\"firstname\", \"middlename\", \"lastname\", \"dob\", \"gender\", \"salary\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f80fdedc-8896-4641-9411-b09fb97f120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy SparkContext từ SparkSession\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93af76c2-dd00-468c-a550-26374e99345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http://spark.apache.org/>\n",
      "guide, on the [project web page](http://spark.apache.org/documentation.html).\n",
      "[\"Building Spark\"](http://spark.apache.org/docs/latest/building-spark.html).\n",
      "For general development tips, including info on developing Spark using an IDE, see [\"Useful Developer Tools\"](http://spark.apache.org/developer-tools.html).\n",
      "    ./bin/spark-shell\n",
      "    ./bin/pyspark\n",
      "examples to a cluster. This can be a mesos:// or spark:// URL,\n",
      "    MASTER=spark://host:7077 ./bin/run-example SparkPi\n",
      "Testing first requires [building Spark](#building-spark). Once Spark is built, tests\n",
      "[run tests for a module, or individual tests](http://spark.apache.org/developer-tools.html#individual-tests).\n",
      "[\"Specifying the Hadoop Version and Enabling YARN\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version-and-enabling-yarn)\n",
      "Please refer to the [Configuration Guide](http://spark.apache.org/docs/latest/configuration.html)\n",
      "Please review the [Contribution to Spark guide](http://spark.apache.org/contributing.html)\n"
     ]
    }
   ],
   "source": [
    "logFile = \"README.md\"\n",
    "logData = sc.textFile(logFile).cache()\n",
    "\n",
    "sparkLines = logData.filter(lambda line: \"spark\" in line)\n",
    "\n",
    "# Hiển thị các dòng chứa \"spark\"\n",
    "for line in sparkLines.collect():\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb4fbd71-203a-4a8a-bdca-8cf3118a812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'Bai1/bai10-output.csv'\n",
    "sparkLines.saveAsTextFile(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af16786-47a9-46e0-8752-dd9827c938f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv(\"Bai1/bai10-df.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb395e17-294c-4357-ae60-b4c65d932010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
